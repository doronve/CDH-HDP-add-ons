#!/bin/bash

export SPARK_HOME=/opt/cloudera/parcels/SPARK2/lib/spark2
export PATH=${PATH}:${SPARK_HOME}/bin
export PYTHONPATH=${PYTHONPATH}:${SPARK_HOME}/python
export PYTHONPATH=${SPARK_HOME}/python/lib/py4j-0.10.6-src.zip:${PYTHONPATH}
export PATH="/opt/cloudera/parcels/Anaconda/bin:$PATH"

myscript=TMPDIR/myhive.py

logfile=/tmp/spark_submit_`date +%Y%m%d_%H%M%S`.log
touch $logfile
hostname

export SPARK_DIST_CLASSPATH="$SPARK_DIST_CLASSPATH:$(hadoop classpath)"

python --version
echo spark-submit
echo spark-submit  >> $logfile
echo ============  >> $logfile
spark-submit \
   --master yarn \
   --deploy-mode client \
   --executor-memory 1g \
   --name myhive \
   --conf "spark.app.id=myhive" $myscript 2 >> $logfile 2> ${logfile}.err

status=$?
echo after spark-submit status=$status
echo after spark-submit status=$status >> $logfile
ls -ld ${logfile}*

